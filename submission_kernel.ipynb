{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- k_v1-0-0: Bert_v1_0 x5fold, relative rank\n",
    "- k_v1-1-0: Bert_v1_0(ep5) x5fold, relative rank\n",
    "- k_v1-1-1: k_v1-1-0 + rule base for question_type_spelling\n",
    "- k_v1-1-3: k_v1-1-0 + rule base for question_type_spelling(v2)\n",
    "\n",
    "- Fork of k_v1-1-3: k_v1-1-3 + Bert_v1_0(tg20,21,22,23,24,25,29)\n",
    "- k_v1-2-1: Fork of k_v1-1-3 + Bert_v1_0_classify(tg12,14,15)(numclass=4)\n",
    "- k_v1-2-3: k_v1-2-1 + Bert_v1_0_classify(tg13)(numclass=5)\n",
    "- k_v1-2-4: k_v1-2-3 + Bert_v1_0(tg0,1,3,5,6,7,16)(numclass=5)\n",
    "- k_v1-2-4-1: k_v1-2-4 + postprocessing(to 0 or 1 using ave+std thresh)\n",
    "- k_v1-2-4-2: k_v1-2-4 + postprocessing(to 0 or 1 using ave+std thresh) - Bert_v1_0_classify(tg12,14,15)(numclass=4)\n",
    "- k_v1-2-4-3: k_v1-2-4-2 + ensemble(except tg13)\n",
    "- k_v1-2-4-4: k_v1-2-4-3 - Bert_v1_0(ep5) + Bert_v1_2\n",
    "- k_v1-2-4-7: k_v1-2-4-4 + ensemble(Bert_v1_0(msk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/google-quest-challenge/train.csv\n",
      "/kaggle/input/google-quest-challenge/test.csv\n",
      "/kaggle/input/google-quest-challenge/sample_submission.csv\n",
      "/kaggle/input/qa-model/20020701_bert_v1_0_msk/Bert_v1_0_model_fold2\n",
      "/kaggle/input/qa-model/20020701_bert_v1_0_msk/Bert_v1_0_model_fold4\n",
      "/kaggle/input/qa-model/20020701_bert_v1_0_msk/Bert_v1_0_model_fold3\n",
      "/kaggle/input/qa-model/20020701_bert_v1_0_msk/Bert_v1_0_model_fold1\n",
      "/kaggle/input/qa-model/20020701_bert_v1_0_msk/log.txt\n",
      "/kaggle/input/qa-model/20020701_bert_v1_0_msk/Bert_v1_0_model_fold0\n",
      "/kaggle/input/qa-model/20020802_bert_v1_0_classify_comb1/Bert_v1_0_clasify_comb1_model_fold1\n",
      "/kaggle/input/qa-model/20020802_bert_v1_0_classify_comb1/tg121415.txt\n",
      "/kaggle/input/qa-model/20020802_bert_v1_0_classify_comb1/Bert_v1_0_clasify_comb1_model_fold2\n",
      "/kaggle/input/qa-model/20020802_bert_v1_0_classify_comb1/Bert_v1_0_clasify_comb1_model_fold0\n",
      "/kaggle/input/qa-model/transformers/bert-base-uncased/tokenizer/vocab.txt\n",
      "/kaggle/input/qa-model/transformers/bert-base-uncased/tokenizer/added_tokens.json\n",
      "/kaggle/input/qa-model/transformers/bert-base-uncased/tokenizer/tokenizer_config.json\n",
      "/kaggle/input/qa-model/transformers/bert-base-uncased/pretrained_model/config.json\n",
      "/kaggle/input/qa-model/transformers/bert-base-uncased/pretrained_model/pytorch_model.bin\n",
      "/kaggle/input/qa-model/20021001_bert_v1_2/Bert_v1_2_model_fold1\n",
      "/kaggle/input/qa-model/20021001_bert_v1_2/Bert_v1_2_model_fold0\n",
      "/kaggle/input/qa-model/20021001_bert_v1_2/log.txt\n",
      "/kaggle/input/qa-model/20021001_bert_v1_2/Bert_v1_2_model_fold2\n",
      "/kaggle/input/qa-model/20021001_bert_v1_2/tg_all.txt\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb1/Bert_v1_0_comb1_model_fold2\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb1/Bert_v1_0_comb1_model_fold1\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb1/tg01356716.txt\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb1/Bert_v1_0_comb1_model_fold0\n",
      "/kaggle/input/qa-model/20020803_bert_v1_0_classify_comb2/Bert_v1_0_clasify_comb2_model_fold0\n",
      "/kaggle/input/qa-model/20020803_bert_v1_0_classify_comb2/tg13numclass5.txt\n",
      "/kaggle/input/qa-model/20020803_bert_v1_0_classify_comb2/Bert_v1_0_clasify_comb2_model_fold1\n",
      "/kaggle/input/qa-model/20020803_bert_v1_0_classify_comb2/Bert_v1_0_clasify_comb2_model_fold2\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb2/Bert_v1_0_comb2_model_fold2\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb2/tg20212223242529.txt\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb2/Bert_v1_0_comb2_model_fold1\n",
      "/kaggle/input/qa-model/20020801_bert_v1_0_comb2/Bert_v1_0_comb2_model_fold0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from math import floor, ceil\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    PATH = '../input/google-quest-challenge/'\n",
    "\n",
    "    BERT_PRETRAINED_MODEL = 'bert-base-uncased'\n",
    "    BERT_TOKENIZER_PATH = '../input/qa-model/transformers/' + BERT_PRETRAINED_MODEL + '/tokenizer/'\n",
    "    BERT_PRETRAINED_MODEL_PATH = '../input/qa-model/transformers/' + BERT_PRETRAINED_MODEL + '/pretrained_model/'\n",
    "\n",
    "    #MY_MODEL = '../input/qa-model/mymodel/20020302_bert_v1_0/'\n",
    "    #MY_MODEL = '../input/qa-model/20020302_bert_v1_0_ep5/'\n",
    "    MY_MODEL = '../input/qa-model/20021001_bert_v1_2/'\n",
    "\n",
    "    MY_MODEL1 = '../input/qa-model/20020701_bert_v1_0_msk/'\n",
    "    \n",
    "    MY_MODEL2 = '../input/qa-model/20020801_bert_v1_0_comb2/' # tg20,21,22,23,24,25,29\n",
    "    TG_MY_MODEL2 = [20,21,22,23,24,25,29]\n",
    "    \n",
    "    #MY_MODEL3_CLASS = '../input/qa-model/20020802_bert_v1_0_classify_comb1/' # tg12,14,15\n",
    "    #TG_MY_MODEL3_CLASS = [12,14,15] # tg12,14,15\n",
    "    \n",
    "    MY_MODEL4_CLASS = '../input/qa-model/20020803_bert_v1_0_classify_comb2/' # tg13\n",
    "    TG_MY_MODEL4_CLASS = [13] # tg13\n",
    "    NUMCLASS_MODEL4_CLASS = 5\n",
    "    \n",
    "    MY_MODEL5 = '../input/qa-model/20020801_bert_v1_0_comb1/' # tg0,1,3,5,6,7,16\n",
    "    TG_MY_MODEL5 = [0,1,3,5,6,7,16]\n",
    "    \n",
    "    POSTPROC_TO_0_INDEX = [2, 9, 12, 14, 15]\n",
    "    POSTPROC_TO_0_C = [1.2, 1.8, 1.6, 1.4, 1.6]\n",
    "    POSTPROC_TO_1_INDEX = [5, ]\n",
    "    POSTPROC_TO_1_C = [0.4, ]\n",
    "    \n",
    "    \n",
    "class InputData:\n",
    "    @staticmethod\n",
    "    def get_train_data(to_relative_rank=False, clip_output=None):\n",
    "        df = pd.read_csv(config.PATH+'train.csv')\n",
    "\n",
    "        if to_relative_rank:\n",
    "            df.iloc[:,11:] = (df.iloc[:,11:].apply(stats.mstats.rankdata, axis=0) - 0.5) / len(df.iloc[:,11:])\n",
    "\n",
    "        if clip_output is not None:\n",
    "            df.iloc[:,11:] = df.iloc[:,11:].clip(clip_output[0], clip_output[1])\n",
    "\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_test_data():\n",
    "        return pd.read_csv(config.PATH+'test.csv')\n",
    "\n",
    "class Submission:\n",
    "    @staticmethod\n",
    "    def get_submission_file():\n",
    "        return pd.read_csv(config.PATH+'sample_submission.csv')\n",
    "\n",
    "    @staticmethod\n",
    "    def make_submission(pred, filename='submission.csv'):\n",
    "        df_sub = Submission.get_submission_file()\n",
    "        df_sub.iloc[:, 1:] = pred\n",
    "        df_sub.to_csv(filename, index=False)\n",
    "        return\n",
    "\n",
    "class BertData_v3:\n",
    "    num_special_token = 3\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_masks(tokens, max_seq_length):\n",
    "        if len(tokens)>max_seq_length:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_segments(tokens, max_seq_length):\n",
    "        \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "        if len(tokens)>max_seq_length:\n",
    "            raise IndexError(\"Token length more than max seq length!\")\n",
    "        segments = []\n",
    "        first_sep = True\n",
    "        current_segment_id = 0\n",
    "        for token in tokens:\n",
    "            segments.append(current_segment_id)\n",
    "            if token == \"[SEP]\":\n",
    "                if first_sep:\n",
    "                    first_sep = False \n",
    "                else:\n",
    "                    current_segment_id = 1\n",
    "        return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_ids(tokens, tokenizer, max_seq_length):\n",
    "        \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "        token_ids = tokenizer.encode(tokens, add_special_tokens=False)\n",
    "        input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "        return input_ids\n",
    "\n",
    "    @staticmethod\n",
    "    def _trim_input(tokenizer, title, body, max_sequence_length, t_max_len=50):\n",
    "        t = tokenizer.tokenize(title)\n",
    "        b = tokenizer.tokenize(body)\n",
    "    \n",
    "        t_len = len(t)\n",
    "        b_len = len(b)\n",
    "\n",
    "        if (t_len + b_len + BertData_v3.num_special_token) > max_sequence_length:\n",
    "            diff = (t_len + b_len + BertData_v3.num_special_token) - max_sequence_length\n",
    "\n",
    "            if t_len > t_max_len:\n",
    "                t_len_new = max(t_max_len, t_len - diff)\n",
    "            else:\n",
    "                t_len_new = t_len\n",
    "\n",
    "            if (t_len_new + b_len + BertData_v3.num_special_token) > max_sequence_length:\n",
    "                b_len_new = max_sequence_length - t_len_new - BertData_v3.num_special_token\n",
    "            else:\n",
    "                b_len_new = b_len\n",
    "\n",
    "            t = t[:t_len_new]\n",
    "            b = b[:b_len_new]\n",
    "\n",
    "        return t, b\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_to_bert_inputs(title, body, tokenizer, max_sequence_length):\n",
    "        \"\"\"Converts tokenized input to ids, masks and segments for BERT\"\"\"\n",
    "    \n",
    "        stoken = [\"[CLS]\"] + title + [\"[SEP]\"] + body + [\"[SEP]\"]\n",
    "\n",
    "        input_ids = BertData_v3._get_ids(stoken, tokenizer, max_sequence_length)\n",
    "        input_masks = BertData_v3._get_masks(stoken, max_sequence_length)\n",
    "        input_segments = BertData_v3._get_segments(stoken, max_sequence_length)\n",
    "\n",
    "        return [input_ids, input_masks, input_segments]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_input_categories(df_train):\n",
    "        return list(df_train.columns[[1,2,5]])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_output_categories(df_train):\n",
    "        return list(df_train.columns[11:])\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_input_arrays(df, tokenizer, max_sequence_length):\n",
    "        columns = BertData_v3.get_input_categories(df)\n",
    "\n",
    "        input_q_ids, input_q_masks, input_q_segments = [], [], []\n",
    "        input_a_ids, input_a_masks, input_a_segments = [], [], []\n",
    "\n",
    "        counter = 0\n",
    "        for _, instance in df[columns].iterrows():\n",
    "            t, q, a = instance.question_title, instance.question_body, instance.answer\n",
    "\n",
    "            t_token, q_token = BertData_v3._trim_input(tokenizer, t, q, max_sequence_length)\n",
    "            ids, masks, segments = BertData_v3._convert_to_bert_inputs(t_token, q_token, tokenizer, max_sequence_length)\n",
    "            input_q_ids.append(ids)\n",
    "            input_q_masks.append(masks)\n",
    "            input_q_segments.append(segments)\n",
    "            \n",
    "            t_token, a_token = BertData_v3._trim_input(tokenizer, t, a, max_sequence_length)\n",
    "            ids, masks, segments = BertData_v3._convert_to_bert_inputs(t_token, a_token, tokenizer, max_sequence_length)\n",
    "            input_a_ids.append(ids)\n",
    "            input_a_masks.append(masks)\n",
    "            input_a_segments.append(segments)\n",
    "            \n",
    "        return [\n",
    "                torch.tensor(np.asarray(input_q_ids, dtype=np.int64)), \n",
    "                torch.tensor(np.asarray(input_q_masks, dtype=np.int64)), \n",
    "                torch.tensor(np.asarray(input_q_segments, dtype=np.int64)),\n",
    "                torch.tensor(np.asarray(input_a_ids, dtype=np.int64)), \n",
    "                torch.tensor(np.asarray(input_a_masks, dtype=np.int64)), \n",
    "                torch.tensor(np.asarray(input_a_segments, dtype=np.int64)),\n",
    "                ]\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_output_arrays(df):\n",
    "        columns = BertData_v3.get_output_categories(df)\n",
    "        return torch.tensor(np.asarray(df[columns]))\n",
    "\n",
    "class BertUtils:\n",
    "    @staticmethod\n",
    "    def save_bert_tokenizer(pretrained_model, save_path):\n",
    "        tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n",
    "        tokenizer.save_pretrained(save_path)\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bert_tokenizer(save_path):\n",
    "        tokenizer = BertTokenizer.from_pretrained(save_path)\n",
    "        return tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def save_bert_model(pretrained_model, save_path):\n",
    "        model = BertModel.from_pretrained(pretrained_model)\n",
    "        model.save_pretrained(save_path)\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bert_model(save_path):\n",
    "        model = BertModel.from_pretrained(save_path)\n",
    "        return model\n",
    "\n",
    "class Bert_v1_0(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_bert_last_hidden=768, num_q_target=21, num_a_target=9, drop_p=0.1):\n",
    "        super(Bert_v1_0, self).__init__()\n",
    "\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        self.q_linear = nn.Linear(num_bert_last_hidden, num_q_target)\n",
    "        self.a_linear = nn.Linear(num_bert_last_hidden*2, num_a_target)\n",
    "\n",
    "    def forward(self, q_id, q_mask, q_seg, a_id, a_mask, a_seg):\n",
    "        oup = self.pretrained_model(q_id, q_mask, q_seg) # (batch, seq length, self.num_bert_last_hidden)\n",
    "        oup = oup[0]\n",
    "        q_hidden_oup = torch.mean(oup, dim=1)\n",
    "        q_oup = self.dropout(q_hidden_oup)\n",
    "\n",
    "        oup = self.pretrained_model(a_id, a_mask, a_seg) # (batch, seq length, self.num_bert_last_hidden)\n",
    "        oup = oup[0]\n",
    "        a_hidden_oup = torch.mean(oup, dim=1)\n",
    "        a_oup = self.dropout(a_hidden_oup)\n",
    "\n",
    "        # q:21, a:9\n",
    "        q_result = self.q_linear(q_oup)\n",
    "        a_result = self.a_linear(torch.cat([q_oup, a_oup], dim=1))\n",
    "\n",
    "        return torch.cat([q_result, a_result], dim=1), torch.cat([q_hidden_oup, a_hidden_oup], dim=1)\n",
    "\n",
    "    def freeze_pretrained_model(self):\n",
    "        for param in self.pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        return\n",
    "\n",
    "class Bert_v1_0_classify(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_class=4, num_bert_last_hidden=768, num_q_target=21, num_a_target=9, drop_p=0.1):\n",
    "        super(Bert_v1_0_classify, self).__init__()\n",
    "\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "\n",
    "        self.q_linears = nn.ModuleList(nn.Linear(num_bert_last_hidden, num_class) for i in range(num_q_target))\n",
    "        self.a_linears = nn.ModuleList(nn.Linear(num_bert_last_hidden*2, num_class) for i in range(num_a_target))\n",
    "\n",
    "    def forward(self, q_id, q_mask, q_seg, a_id, a_mask, a_seg):\n",
    "        # q out\n",
    "        oup = self.pretrained_model(q_id, q_mask, q_seg) # (batch, seq length, self.num_bert_last_hidden)\n",
    "        oup = oup[0]\n",
    "        q_hidden_oup = torch.mean(oup, dim=1)\n",
    "        q_oup = self.dropout(q_hidden_oup)\n",
    "\n",
    "        # a out\n",
    "        oup = self.pretrained_model(a_id, a_mask, a_seg) # (batch, seq length, self.num_bert_last_hidden)\n",
    "        oup = oup[0]\n",
    "        a_hidden_oup = torch.mean(oup, dim=1)\n",
    "        a_oup = self.dropout(a_hidden_oup)\n",
    "\n",
    "        # results [(batch, class), (batch, class), ...]\n",
    "        results = []\n",
    "        # q:21\n",
    "        for q_linear in self.q_linears:\n",
    "            results.append(torch.unsqueeze(q_linear(q_oup), 1))\n",
    "        # a:9\n",
    "        for a_linear in self.a_linears:\n",
    "            results.append(torch.unsqueeze(a_linear(torch.cat([q_oup, a_oup], dim=1)), 1))\n",
    "        \n",
    "        return torch.cat(results, dim=1), torch.cat([q_hidden_oup, a_hidden_oup], dim=1)\n",
    "\n",
    "    def freeze_pretrained_model(self):\n",
    "        for param in self.pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        return\n",
    "    \n",
    "class Bert_v1_2(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_bert_last_hidden=768, num_q_target=21, num_a_target=9, drop_p=0.1):\n",
    "        super(Bert_v1_2, self).__init__()\n",
    "\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "        self.q_linear = nn.Linear(num_bert_last_hidden, num_q_target)\n",
    "        self.a_linear = nn.Linear(num_bert_last_hidden, num_a_target)\n",
    "\n",
    "    def forward(self, q_id, q_mask, q_seg, a_id, a_mask, a_seg):\n",
    "        oup = self.pretrained_model(q_id, q_mask, q_seg) # (batch, seq length, self.num_bert_last_hidden)\n",
    "        oup = oup[0]\n",
    "        q_hidden_oup = torch.mean(oup, dim=1)\n",
    "        q_oup = self.dropout(q_hidden_oup)\n",
    "\n",
    "        oup = self.pretrained_model(a_id, a_mask, a_seg) # (batch, seq length, self.num_bert_last_hidden)\n",
    "        oup = oup[0]\n",
    "        a_hidden_oup = torch.mean(oup, dim=1)\n",
    "        a_oup = self.dropout(a_hidden_oup)\n",
    "\n",
    "        # q:21, a:9\n",
    "        q_result = self.q_linear(q_oup)\n",
    "        a_result = self.a_linear(a_oup)\n",
    "\n",
    "        return torch.cat([q_result, a_result], dim=1), torch.cat([q_hidden_oup, a_hidden_oup], dim=1)\n",
    "    \n",
    "class QADataset_SeparateQA(torch.utils.data.Dataset):\n",
    "    def __init__(self, q_ids, q_masks, q_segments, a_ids, a_masks, a_segments, labels=None):\n",
    "        self.q_ids = q_ids\n",
    "        self.q_masks = q_masks\n",
    "        self.q_segments = q_segments\n",
    "        self.a_ids = a_ids\n",
    "        self.a_masks = a_masks\n",
    "        self.a_segments = a_segments\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.q_ids[idx], self.q_masks[idx], self.q_segments[idx], self.a_ids[idx], self.a_masks[idx], self.a_segments[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.q_ids[idx], self.q_masks[idx], self.q_segments[idx], self.a_ids[idx], self.a_masks[idx], self.a_segments[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.q_ids)\n",
    "\n",
    "def get_dataloader(dataset, batch_size, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "def compute_spearmanr(original, preds):\n",
    "    scores = []\n",
    "    for i in range(30):\n",
    "        scores.append(spearmanr(original[:, i], preds[:, i]).correlation)\n",
    "\n",
    "    return np.nanmean(scores)\n",
    "\n",
    "def sigmoid(x):\n",
    "    y = 1 / (1 + np.exp(-x))\n",
    "    return y\n",
    "\n",
    "def calc_pred_Bert_v1_0(net, dataloader, with_target=False, classify=False):\n",
    "    net = net.cuda()\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    preds = []\n",
    "    original = []\n",
    "    if with_target:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (q_ids, q_masks, q_segments, a_ids, a_masks, a_segments, targets) in enumerate(tqdm(dataloader)):\n",
    "                q_ids, q_masks, q_segments, targets = q_ids.cuda(), q_masks.cuda(), q_segments.cuda(), targets.cuda()\n",
    "                a_ids, a_masks, a_segments = a_ids.cuda(), a_masks.cuda(), a_segments.cuda()\n",
    "                outputs, hidden_outpus = net(q_ids, q_masks, q_segments, a_ids, a_masks, a_segments)\n",
    "\n",
    "                if not classify:\n",
    "                    preds.append(outputs.cpu().numpy())\n",
    "                else:\n",
    "                    preds.append(outputs.max(2)[1].cpu().numpy())\n",
    "                original.append(targets.cpu().numpy())\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (q_ids, q_masks, q_segments, a_ids, a_masks, a_segments) in enumerate(tqdm(dataloader)):\n",
    "                q_ids, q_masks, q_segments = q_ids.cuda(), q_masks.cuda(), q_segments.cuda()\n",
    "                a_ids, a_masks, a_segments = a_ids.cuda(), a_masks.cuda(), a_segments.cuda()\n",
    "                outputs, hidden_outpus = net(q_ids, q_masks, q_segments, a_ids, a_masks, a_segments)\n",
    "\n",
    "                if not classify:\n",
    "                    preds.append(outputs.cpu().numpy())\n",
    "                else:\n",
    "                    preds.append(outputs.max(2)[1].cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    preds = sigmoid(preds)\n",
    "\n",
    "    if with_target:\n",
    "        original = np.concatenate(original)    \n",
    "        score = compute_spearmanr(original, preds)\n",
    "        print('Score: %.5f' % (score,))\n",
    "\n",
    "    return preds\n",
    "\n",
    "def calc_pred_question_type_spelling(data_df):\n",
    "    print('calc_pred_question_type_spelling')\n",
    "    # category, host\n",
    "    ex_x = data_df[data_df['category']=='CULTURE']\n",
    "    print(len(ex_x))\n",
    "    ex_x = ex_x[ex_x['host']=='english.stackexchange.com']\n",
    "    print(len(ex_x))\n",
    "\n",
    "    qts = ex_x['question_title']\n",
    "    posi = []\n",
    "    for qt in qts:\n",
    "        words = qt.split(' ')\n",
    "    #    or_flg = []\n",
    "    #    or_flg.append('pronounce' in words)\n",
    "    #    or_flg.append('pronunciation' in words)\n",
    "    #    or_flg.append('sounds' in words)\n",
    "    #    or_flg.append('sound' in words)\n",
    "    #    or_flg.append('spell' in words)\n",
    "    #    or_flg.append('spells' in words)\n",
    "    #    or_flg.append('spelling' in words)\n",
    "    #    or_flg.append('accent' in words)\n",
    "    #    or_flg.append('accented' in words)\n",
    "    #    or_flg.append('vowel' in words)\n",
    "    #    or_flg.append('schwa' in words)\n",
    "    #    or_flg.append('syllables' in words)\n",
    "    #    or_flg.append('phoneme' in words)\n",
    "    #    #or_flg.append('or' in words)\n",
    "    #    #or_flg.append('and' in words)\n",
    "    #        \n",
    "        and_flg = []\n",
    "        and_flg.append(not 'mean' in words)\n",
    "        and_flg.append(not 'mean.' in words)\n",
    "        and_flg.append(not 'mean?' in words)\n",
    "        and_flg.append(not 'means' in words)\n",
    "        and_flg.append(not 'means.' in words)\n",
    "        and_flg.append(not 'means?' in words)\n",
    "        and_flg.append(not 'meaning' in words)\n",
    "        and_flg.append(not 'meaning.' in words)\n",
    "        and_flg.append(not 'meaning?' in words)\n",
    "        and_flg.append(not 'use' in words)\n",
    "        and_flg.append(not 'use.' in words)\n",
    "        and_flg.append(not 'use?' in words)\n",
    "        and_flg.append(not 'uses' in words)\n",
    "        and_flg.append(not 'uses.' in words)\n",
    "        and_flg.append(not 'uses?' in words)\n",
    "        and_flg.append(not 'using' in words)\n",
    "        and_flg.append(not 'using.' in words)\n",
    "        and_flg.append(not 'using?' in words)\n",
    "        and_flg.append(not 'used' in words)\n",
    "        and_flg.append(not 'used.' in words)\n",
    "        and_flg.append(not 'used?' in words)\n",
    "\n",
    "        #if any(or_flg) and all(and_flg):\n",
    "        if all(and_flg):\n",
    "            posi.append(1)\n",
    "            print(qt)\n",
    "        else:\n",
    "            posi.append(0)\n",
    "\n",
    "    posi = np.array(posi)    \n",
    "    if np.all(posi < 0.5):\n",
    "        print('all 0 in calc_pred_question_type_spelling')\n",
    "        posi = 1\n",
    "\n",
    "    pred = np.zeros(len(data_df))\n",
    "    #pred[ex_x.index] = 1\n",
    "    pred[ex_x.index] = posi\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_proc_to0or1(pred):\n",
    "    # to 0\n",
    "    for idx, c in zip(config.POSTPROC_TO_0_INDEX, config.POSTPROC_TO_0_C):\n",
    "        tg = pred[:,idx].copy()\n",
    "        cond = tg < np.average(tg) + np.std(tg) * c\n",
    "        pred[cond,idx] = 0.00001\n",
    "        \n",
    "    # to 1\n",
    "    for idx, c in zip(config.POSTPROC_TO_1_INDEX, config.POSTPROC_TO_1_C):\n",
    "        tg = pred[:,idx].copy()\n",
    "        cond = tg > np.average(tg) - np.std(tg) * c\n",
    "        pred[cond,idx] = 0.99999\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20020401():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    # prediction\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20020601():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    # prediction\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    # predcition by rule base\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_200208801():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = pred2[:,config.TG_MY_MODEL2]\n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_200208802():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path3_class = [\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = pred2[:,config.TG_MY_MODEL2]\n",
    "    \n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_200208803():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path3_class = [\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = pred2[:,config.TG_MY_MODEL2]\n",
    "    \n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20021001():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path3_class = [\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path5 = [\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = pred2[:,config.TG_MY_MODEL2]\n",
    "    \n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    # prediction5\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict5')\n",
    "    pred5 = None\n",
    "    counter = 0\n",
    "    for mp in model_path5:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred5 is None:\n",
    "            pred5 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred5 = pred5 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred5 = pred5 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL5] = pred5[:,config.TG_MY_MODEL5]\n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20021002():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path3_class = [\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path5 = [\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = pred2[:,config.TG_MY_MODEL2]\n",
    "    \n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    # prediction5\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict5')\n",
    "    pred5 = None\n",
    "    counter = 0\n",
    "    for mp in model_path5:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred5 is None:\n",
    "            pred5 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred5 = pred5 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred5 = pred5 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL5] = pred5[:,config.TG_MY_MODEL5]\n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # post processing to 0 or 1\n",
    "    print('post processing to 0 or 1')\n",
    "    pred = post_proc_to0or1(pred)\n",
    "    \n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20021003():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    #model_path3_class = [\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "    #    ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path5 = [\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = pred2[:,config.TG_MY_MODEL2]\n",
    "    \n",
    "    \"\"\"\n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \"\"\"\n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    # prediction5\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict5')\n",
    "    pred5 = None\n",
    "    counter = 0\n",
    "    for mp in model_path5:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred5 is None:\n",
    "            pred5 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred5 = pred5 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred5 = pred5 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL5] = pred5[:,config.TG_MY_MODEL5]\n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # post processing to 0 or 1\n",
    "    print('post processing to 0 or 1')\n",
    "    pred = post_proc_to0or1(pred)\n",
    "    \n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20021101():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    #model_path3_class = [\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "    #    ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path5 = [\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = (pred[:,config.TG_MY_MODEL2] + pred2[:,config.TG_MY_MODEL2]) * 0.5\n",
    "    \n",
    "    \"\"\"\n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \"\"\"\n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    # prediction5\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict5')\n",
    "    pred5 = None\n",
    "    counter = 0\n",
    "    for mp in model_path5:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred5 is None:\n",
    "            pred5 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred5 = pred5 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred5 = pred5 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL5] = (pred[:,config.TG_MY_MODEL5] + pred5[:,config.TG_MY_MODEL5]) * 0.5\n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # post processing to 0 or 1\n",
    "    print('post processing to 0 or 1')\n",
    "    pred = post_proc_to0or1(pred)\n",
    "    \n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20021102():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    #model_path3_class = [\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "    #    ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path5 = [\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    model = Bert_v1_2(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction2\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL2] = (pred[:,config.TG_MY_MODEL2] + pred2[:,config.TG_MY_MODEL2]) * 0.5\n",
    "    \n",
    "    \"\"\"\n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \"\"\"\n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    # prediction5\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict5')\n",
    "    pred5 = None\n",
    "    counter = 0\n",
    "    for mp in model_path5:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred5 is None:\n",
    "            pred5 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred5 = pred5 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred5 = pred5 / counter\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL5] = (pred[:,config.TG_MY_MODEL5] + pred5[:,config.TG_MY_MODEL5]) * 0.5\n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # post processing to 0 or 1\n",
    "    print('post processing to 0 or 1')\n",
    "    pred = post_proc_to0or1(pred)\n",
    "    \n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_20021103():\n",
    "    DO_CHECK = False\n",
    "\n",
    "    print('model')\n",
    "    pretrained_model = config.BERT_PRETRAINED_MODEL\n",
    "    pretrained_tokenizer_path = config.BERT_TOKENIZER_PATH\n",
    "    pretrained_model_path = config.BERT_PRETRAINED_MODEL_PATH\n",
    "    max_sequence_length = 512\n",
    "\n",
    "    tokenizer = BertUtils.get_bert_tokenizer(pretrained_tokenizer_path)\n",
    "    \n",
    "    model_path = [\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL, 'Bert_v1_2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path1 = [\n",
    "        os.path.join(config.MY_MODEL1, 'Bert_v1_0_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL1, 'Bert_v1_0_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL1, 'Bert_v1_0_model_fold2'),\n",
    "        os.path.join(config.MY_MODEL1, 'Bert_v1_0_model_fold3'),\n",
    "        os.path.join(config.MY_MODEL1, 'Bert_v1_0_model_fold4'),\n",
    "        ]\n",
    "    \n",
    "    model_path2 = [\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL2, 'Bert_v1_0_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    #model_path3_class = [\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold0'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold1'),\n",
    "    #    os.path.join(config.MY_MODEL3_CLASS, 'Bert_v1_0_clasify_comb1_model_fold2'),\n",
    "    #    ]\n",
    "    \n",
    "    model_path4_class = [\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL4_CLASS, 'Bert_v1_0_clasify_comb2_model_fold2'),\n",
    "        ]\n",
    "    \n",
    "    model_path5 = [\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold0'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold1'),\n",
    "        os.path.join(config.MY_MODEL5, 'Bert_v1_0_comb1_model_fold2'),\n",
    "        ]\n",
    "\n",
    "\n",
    "    print('test data')\n",
    "    # raw data\n",
    "    test_df = InputData.get_test_data()\n",
    "    # bert input\n",
    "    test_bert_inp = BertData_v3.compute_input_arrays(test_df, tokenizer, max_sequence_length)\n",
    "    \n",
    "    # prediction\n",
    "    model = Bert_v1_2(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict')\n",
    "    pred = None\n",
    "    counter = 0\n",
    "    for mp in model_path:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred is None:\n",
    "            pred = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred = pred / counter\n",
    "    \n",
    "    # prediction1\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict')\n",
    "    pred1 = None\n",
    "    counter = 0\n",
    "    for mp in model_path1:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred1 is None:\n",
    "            pred1 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred1 = pred1 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred1 = pred1 / counter\n",
    "    pred = (pred + pred1) * 0.5\n",
    "    \n",
    "    \n",
    "    # prediction2\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict2')\n",
    "    pred2 = None\n",
    "    counter = 0\n",
    "    for mp in model_path2:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred2 is None:\n",
    "            pred2 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred2 = pred2 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred2 = pred2 / counter\n",
    "    \n",
    "    #pred[:,config.TG_MY_MODEL2] = (pred[:,config.TG_MY_MODEL2] + pred2[:,config.TG_MY_MODEL2]) * 0.5\n",
    "    pred[:,config.TG_MY_MODEL2] = (pred[:,config.TG_MY_MODEL2] * 2 + pred2[:,config.TG_MY_MODEL2] * 1) / 3\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # prediction3\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict3')\n",
    "    pred3 = None\n",
    "    counter = 0\n",
    "    for mp in model_path3_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred3 is None:\n",
    "            pred3 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred3 = pred3 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred3 = pred3 / counter\n",
    "    pred3 = pred3 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL3_CLASS] = pred3[:,config.TG_MY_MODEL3_CLASS]\n",
    "    \"\"\"\n",
    "    \n",
    "    # prediction4\n",
    "    model_cls = Bert_v1_0_classify(BertUtils.get_bert_model(pretrained_model_path), num_class=config.NUMCLASS_MODEL4_CLASS)\n",
    "    print('predict4')\n",
    "    pred4 = None\n",
    "    counter = 0\n",
    "    for mp in model_path4_class:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model_cls.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred4 is None:\n",
    "            pred4 = calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        else:\n",
    "            pred4 = pred4 + calc_pred_Bert_v1_0(model_cls, loader, with_target=False, classify=True)\n",
    "        counter += 1\n",
    "    pred4 = pred4 / counter\n",
    "    pred4 = pred4 / 100 # convert value to less than 1\n",
    "    \n",
    "    pred[:,config.TG_MY_MODEL4_CLASS] = pred4[:,config.TG_MY_MODEL4_CLASS]\n",
    "    \n",
    "    # prediction5\n",
    "    model = Bert_v1_0(BertUtils.get_bert_model(pretrained_model_path))\n",
    "    print('predict5')\n",
    "    pred5 = None\n",
    "    counter = 0\n",
    "    for mp in model_path5:\n",
    "        ds = QADataset_SeparateQA(test_bert_inp[0], test_bert_inp[1], test_bert_inp[2], \n",
    "                                  test_bert_inp[3], test_bert_inp[4], test_bert_inp[5])\n",
    "\n",
    "        batch_size = 32\n",
    "        loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "        model.load_state_dict(torch.load(mp))\n",
    "\n",
    "        if pred5 is None:\n",
    "            pred5 = calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        else:\n",
    "            pred5 = pred5 + calc_pred_Bert_v1_0(model, loader, with_target=False)\n",
    "        counter += 1\n",
    "    pred5 = pred5 / counter\n",
    "    \n",
    "    #pred[:,config.TG_MY_MODEL5] = (pred[:,config.TG_MY_MODEL5] + pred5[:,config.TG_MY_MODEL5]) * 0.5\n",
    "    pred[:,config.TG_MY_MODEL5] = (pred[:,config.TG_MY_MODEL5] * 2 + pred5[:,config.TG_MY_MODEL5] * 1) / 3\n",
    "    \n",
    "    \n",
    "    \n",
    "    # predcition by rule base\n",
    "    print('predcition by rule base')\n",
    "    pred_question_type_spelling = calc_pred_question_type_spelling(test_df)\n",
    "    pred[:,19] = pred_question_type_spelling\n",
    "\n",
    "    # post processing to 0 or 1\n",
    "    print('post processing to 0 or 1')\n",
    "    pred = post_proc_to0or1(pred)\n",
    "    \n",
    "    # make submission\n",
    "    print('submission')\n",
    "    Submission.make_submission(pred)\n",
    "\n",
    "    if DO_CHECK:\n",
    "        print('train data')\n",
    "        # raw data\n",
    "        train_df = InputData.get_train_data()\n",
    "        # bert input\n",
    "        train_bert_inp = BertData_v3.compute_input_arrays(train_df, tokenizer, max_sequence_length)\n",
    "        train_bert_label = BertData_v3.compute_output_arrays(train_df) # 30\n",
    "        # prediction\n",
    "        pred = None\n",
    "        counter = 0\n",
    "        for mp in model_path:\n",
    "            ds = QADataset_SeparateQA(train_bert_inp[0], train_bert_inp[1], train_bert_inp[2], \n",
    "                                      train_bert_inp[3], train_bert_inp[4], train_bert_inp[5],\n",
    "                                      train_bert_label)\n",
    "\n",
    "            batch_size = 32\n",
    "            loader = get_dataloader(ds, batch_size, shuffle=False)\n",
    "\n",
    "            model.load_state_dict(torch.load(mp))\n",
    "\n",
    "            if pred is None:\n",
    "                pred = calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            else:\n",
    "                pred = pred + calc_pred_Bert_v1_0(model, loader, with_target=True)\n",
    "            counter += 1\n",
    "        pred = pred / counter\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "        # predcition by rule base\n",
    "        pred_question_type_spelling = calc_pred_question_type_spelling(train_df)\n",
    "        pred[:,19] = pred_question_type_spelling\n",
    "        # make submission\n",
    "        score = compute_spearmanr(train_bert_label, pred)\n",
    "        print('train data score : {0}'.format(score))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "test data\n",
      "predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec3d71f43ca4c3694d2516808da756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47f7fa0a1e542afbcbe941c7cbc0ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab740baadafa4c62a323279cdf3a43d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e0dc86b0cc4559a3e23b4a9394969b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acda71f06476487b982891209ff3f9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14944c852437470db22d97fb3aa95844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89e5a68206047d5b40c9b7dbfd8562b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c15905b57544afa6ec870b1491908d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d1f8900efb43a985658e73702e764f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aee7dc55385459f9fec026e61db3657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eaca0a050f64cd685249da440889b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668286597da04ba691a0aff0773c73ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4162acd606694f3c811b2a08188b5c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ba0d983a454ac3add2d2d9e15be527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predict5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7647d63e14c2431a94b40f702d7b0a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6976de2fda406dbdbef6fb439da801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa927175110e4436a3732f3ac9e3c421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predcition by rule base\n",
      "calc_pred_question_type_spelling\n",
      "64\n",
      "7\n",
      "What word describes the action of changing the grammatical person of a sentence?\n",
      "Positive way of saying emotional appeal?\n",
      "\"Report by\" or \"report from\"\n",
      "What is the correct possessive form of \"One of the guys\"?\n",
      "post processing to 0 or 1\n",
      "submission\n"
     ]
    }
   ],
   "source": [
    "#run_20020401()\n",
    "#run_20020601()\n",
    "#run_200208801()\n",
    "#run_200208802()\n",
    "#run_200208803()\n",
    "#run_20021001()\n",
    "#run_20021002()\n",
    "#run_20021003()\n",
    "#run_20021101()\n",
    "#run_20021102()\n",
    "run_20021103()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00aa96b298df41e08182b8da081200e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6700afedb82440498e2481289a006a9d",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ffa5a42f8eeb40d0b9fb6c28d4e44410",
       "value": 15.0
      }
     },
     "03edbeccdd6c40cf887991ecf1091ed9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0422b475dc634204a4ac966c0a59750b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "04270445ac9e4d6cbababf531beddd74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "04615368d5604dc4813d1283af6e1731": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "056092afdebd498888f8c56df8ec8f59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a2154a33cf0453fad6a23326b0ab842": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d903b071abc4b73a65ac3712432a1a5",
       "placeholder": "​",
       "style": "IPY_MODEL_62ad1439cffd460c91887fd50c69ba66",
       "value": " 15/15 [00:16&lt;00:00,  1.12s/it]"
      }
     },
     "0adfbc875fd143068d247f8f60b48595": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b43f2fab94e46b098633a7a08320e19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee71222b373b490cb44e30468035b3d5",
       "placeholder": "​",
       "style": "IPY_MODEL_62c09fb9fb1241f88f0dc6e562a6c722",
       "value": " 15/15 [00:16&lt;00:00,  1.12s/it]"
      }
     },
     "0bdfd4deb1de498ab83564f55636ec90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0cf40d030a324a898b8f2647334778e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7fcdbd79e3ae413d8a2611e80d0ded8a",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4fa556787bfc4e878cba3d63cb978045",
       "value": 15.0
      }
     },
     "0ec3d71f43ca4c3694d2516808da756e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0cf40d030a324a898b8f2647334778e0",
        "IPY_MODEL_19f311bf043e4a21afbd47094e546fea"
       ],
       "layout": "IPY_MODEL_de088b18db7347d9ac1ffebc4520e040"
      }
     },
     "0f551bdb39a5462e9ef3be67bf6f7716": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae2d36cb8eac4c5094fe7b11f935d74a",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_12a2ad2493a3437e85456b41abec29a8",
       "value": 15.0
      }
     },
     "0f6d0cfd033843b99ab50bb998aad432": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "12a2ad2493a3437e85456b41abec29a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "14944c852437470db22d97fb3aa95844": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_309295f2f21642b0948a828b5d5e142e",
        "IPY_MODEL_7839f8d1d89c41eaba7c8d7436f3df9a"
       ],
       "layout": "IPY_MODEL_76a45f4f27ce4eb5bdb643598a66f269"
      }
     },
     "15252f6c0c0445ffb02b7fa878db0cc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "158e424155e4426397701149a3478fa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1f42de082cf4406ca734b62d7513ad15",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_15252f6c0c0445ffb02b7fa878db0cc5",
       "value": 15.0
      }
     },
     "18fce1cc1de64899bc2326647c5ae36c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "19f311bf043e4a21afbd47094e546fea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5a49919e0e2c4561a78271774a7649c4",
       "placeholder": "​",
       "style": "IPY_MODEL_0f6d0cfd033843b99ab50bb998aad432",
       "value": " 15/15 [00:51&lt;00:00,  3.43s/it]"
      }
     },
     "1cad92fea47b40cab2fae6a3a57c4880": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1d2c971b394c444ab56d697cc3836c30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1f42de082cf4406ca734b62d7513ad15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2390d0b5b0e8429f96fa3cdd2b99deaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_27c68c8ad35c4613abfeb90968f191ac",
       "placeholder": "​",
       "style": "IPY_MODEL_50c67de8e16947f7a154079229d5f137",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "24d1f8900efb43a985658e73702e764f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_618871a81b54471c96d10630ccd037e1",
        "IPY_MODEL_c7657771be87496ba1cabe8e88587c2b"
       ],
       "layout": "IPY_MODEL_d41109ef9b6940dc984079ad9beba801"
      }
     },
     "25ceb38ed0b145668ee8c4632270f839": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27a03a35162c42ca8f1f799848849f73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27c68c8ad35c4613abfeb90968f191ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "280f58e38ef8452ea1717010ab418f7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9160f2ec9a754c5eb4306f9616007d3f",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b4f0e607f69a4c7c95dd63df77789bf5",
       "value": 15.0
      }
     },
     "2df20da79c4547a69b7a31897964b965": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ebef13bbd30c4c8b9e534c0003f29d87",
       "placeholder": "​",
       "style": "IPY_MODEL_1d2c971b394c444ab56d697cc3836c30",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "2f4ec60273ae4b2198ec533b594933d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "309295f2f21642b0948a828b5d5e142e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_27a03a35162c42ca8f1f799848849f73",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f48d5d040bb4455bb40283599fff7608",
       "value": 15.0
      }
     },
     "31ba0d983a454ac3add2d2d9e15be527": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_158e424155e4426397701149a3478fa5",
        "IPY_MODEL_4af29c5d7d27410b9b93b4688ffa4318"
       ],
       "layout": "IPY_MODEL_63c0d9f5aae0485e9d555f53072f8fab"
      }
     },
     "31fe7b1f74d0433682493dab2cdf6e52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_46f2cdf6a22a41a7bfbc11d93f548ba9",
       "placeholder": "​",
       "style": "IPY_MODEL_04270445ac9e4d6cbababf531beddd74",
       "value": " 15/15 [00:16&lt;00:00,  1.12s/it]"
      }
     },
     "37aa7d7c04d84d189f151b36773a3a8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3934ebe43c524629a608df1492b3674e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3b29e25a0e734deca31c14374eca3cf6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4106848f3659478aa9d4c49304872053": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4162acd606694f3c811b2a08188b5c52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9e7a9bca34eb48e1a177b41b984e212a",
        "IPY_MODEL_ceb5c908b9e14c7bb4fcf620ac9225a7"
       ],
       "layout": "IPY_MODEL_68821e2a228e4ee79520cbfd85b070f5"
      }
     },
     "45e0dc86b0cc4559a3e23b4a9394969b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_00aa96b298df41e08182b8da081200e5",
        "IPY_MODEL_c7c672f7da0e4a7da0e424a3d771184c"
       ],
       "layout": "IPY_MODEL_b7f13694fa064d2798e58ba0b8dcc644"
      }
     },
     "46c0131e8bd748f7993fc285b2ea4916": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "46f2cdf6a22a41a7bfbc11d93f548ba9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4af29c5d7d27410b9b93b4688ffa4318": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8d127962b57f4f0ca659e475f63146cd",
       "placeholder": "​",
       "style": "IPY_MODEL_e5b01966cec44e918b312e287db0bd56",
       "value": " 15/15 [00:16&lt;00:00,  1.12s/it]"
      }
     },
     "4f1d34167831473784ee43d8398aedae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fa556787bfc4e878cba3d63cb978045": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "50c67de8e16947f7a154079229d5f137": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "52e7430e8b624e80a198e5bef5d08d14": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "536ccdc02e3d44238f5c2e2c4d003824": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d6844c8a87b344f29f453d141a2d56d1",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f8783837c5274aada680cb22d7fe904b",
       "value": 15.0
      }
     },
     "5932977031714d8a957e2c6f4e92782d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5a49919e0e2c4561a78271774a7649c4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5abe922ee64f4d21929e67603c1c9619": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dca14628b35d420e843d32fca05476ff",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4106848f3659478aa9d4c49304872053",
       "value": 15.0
      }
     },
     "5aee7dc55385459f9fec026e61db3657": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_98c2905f67f04475a1838f55bafef5b9",
        "IPY_MODEL_7706f946cbb84471a1c501fbbd856615"
       ],
       "layout": "IPY_MODEL_897a9857c2c744c0836c62e291514a6f"
      }
     },
     "5d903b071abc4b73a65ac3712432a1a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60b57f5835be41bf8740671531656c1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_97d2c2830f7741fcbdc3f4c2b8b2f5fa",
       "placeholder": "​",
       "style": "IPY_MODEL_999e362586514d8fb87d6a31ac2ce46a",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "60d8817ba0b9421eb7c0118d3c915104": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fac6c93ab7240e8a64ba61492b97e4d",
       "placeholder": "​",
       "style": "IPY_MODEL_fc5277289c284541af766d05e24351e2",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "618871a81b54471c96d10630ccd037e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f6fea3f5d42542abb8796fafb0914d66",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_46c0131e8bd748f7993fc285b2ea4916",
       "value": 15.0
      }
     },
     "62ad1439cffd460c91887fd50c69ba66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "62c09fb9fb1241f88f0dc6e562a6c722": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63c0d9f5aae0485e9d555f53072f8fab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "668286597da04ba691a0aff0773c73ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5abe922ee64f4d21929e67603c1c9619",
        "IPY_MODEL_681650ad64ba4d4da8fdc652bcbcc240"
       ],
       "layout": "IPY_MODEL_4f1d34167831473784ee43d8398aedae"
      }
     },
     "6700afedb82440498e2481289a006a9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "671f342fb94f43cfaf4b11b7b116caae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67e48ebfe9db4b488a51825967025197": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_709ea2ada85f4672b543871bcc330cb3",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3b29e25a0e734deca31c14374eca3cf6",
       "value": 15.0
      }
     },
     "681650ad64ba4d4da8fdc652bcbcc240": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fc3264e7e63440bcb3e5d40bec8dd94e",
       "placeholder": "​",
       "style": "IPY_MODEL_d9a971b204ff4458b182bf13f8ef157d",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "68821e2a228e4ee79520cbfd85b070f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69d513abd8c347f1ad04a65f255d1e48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c4ca230b94b4d978ad24ab33ed9d37e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d64d297b7534e1a887885cc11d620f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_52e7430e8b624e80a198e5bef5d08d14",
       "placeholder": "​",
       "style": "IPY_MODEL_c4aa9b36bb33403d9163ad62195dff70",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "6fac6c93ab7240e8a64ba61492b97e4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "709ea2ada85f4672b543871bcc330cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7647d63e14c2431a94b40f702d7b0a9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f551bdb39a5462e9ef3be67bf6f7716",
        "IPY_MODEL_2390d0b5b0e8429f96fa3cdd2b99deaf"
       ],
       "layout": "IPY_MODEL_0bdfd4deb1de498ab83564f55636ec90"
      }
     },
     "76a45f4f27ce4eb5bdb643598a66f269": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7706f946cbb84471a1c501fbbd856615": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_907c9263f67c4d5f856c2803df2a4422",
       "placeholder": "​",
       "style": "IPY_MODEL_7f87841ec4004eb9b70576b155b3a5b0",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "7839f8d1d89c41eaba7c8d7436f3df9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_056092afdebd498888f8c56df8ec8f59",
       "placeholder": "​",
       "style": "IPY_MODEL_5932977031714d8a957e2c6f4e92782d",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "796c5e65527241db96a35ea1a8800397": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_69d513abd8c347f1ad04a65f255d1e48",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f83f7f09820c4aa8aef584dc4bdb368e",
       "value": 15.0
      }
     },
     "7f0a4c73dd784daab1a0eb44703bd06c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_37aa7d7c04d84d189f151b36773a3a8b",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ca5fc76012f44ab4a603b7b1cff3a5d5",
       "value": 15.0
      }
     },
     "7f87841ec4004eb9b70576b155b3a5b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7fcdbd79e3ae413d8a2611e80d0ded8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88e92dd561f7441bae03b4fe4613d3a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "897a9857c2c744c0836c62e291514a6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8cc7d03761254f76b58c1c846ee497d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "8d127962b57f4f0ca659e475f63146cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "907c9263f67c4d5f856c2803df2a4422": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9160f2ec9a754c5eb4306f9616007d3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97d2c2830f7741fcbdc3f4c2b8b2f5fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98c2905f67f04475a1838f55bafef5b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_eb8e8ae439cc498181e79abc3d96b036",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8cc7d03761254f76b58c1c846ee497d9",
       "value": 15.0
      }
     },
     "999e362586514d8fb87d6a31ac2ce46a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9a2dba31274d4e41af34e829169c875c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_03edbeccdd6c40cf887991ecf1091ed9",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0422b475dc634204a4ac966c0a59750b",
       "value": 15.0
      }
     },
     "9e7a9bca34eb48e1a177b41b984e212a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cdfc3d8d85ac496d91e04e8cd89514fe",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e6de69b902e44371a8f06dabdded14be",
       "value": 15.0
      }
     },
     "9eaca0a050f64cd685249da440889b57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7f0a4c73dd784daab1a0eb44703bd06c",
        "IPY_MODEL_0a2154a33cf0453fad6a23326b0ab842"
       ],
       "layout": "IPY_MODEL_d2c88f18db494b2ab395e9ae32fed6cb"
      }
     },
     "a747496e51214ebb99dbd436f5c7ca49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a9fa9c8786a74f21bd3eb851f107219b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0adfbc875fd143068d247f8f60b48595",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b27246bc159e42fcb36a387feb59e5eb",
       "value": 15.0
      }
     },
     "aa927175110e4436a3732f3ac9e3c421": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_796c5e65527241db96a35ea1a8800397",
        "IPY_MODEL_60d8817ba0b9421eb7c0118d3c915104"
       ],
       "layout": "IPY_MODEL_b1d1354e458d42cb8fe1ac8e2664af61"
      }
     },
     "ab740baadafa4c62a323279cdf3a43d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_67e48ebfe9db4b488a51825967025197",
        "IPY_MODEL_0b43f2fab94e46b098633a7a08320e19"
       ],
       "layout": "IPY_MODEL_fc2ae269bec54770bea39b45af3e6f65"
      }
     },
     "acda71f06476487b982891209ff3f9e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_280f58e38ef8452ea1717010ab418f7a",
        "IPY_MODEL_2df20da79c4547a69b7a31897964b965"
       ],
       "layout": "IPY_MODEL_3934ebe43c524629a608df1492b3674e"
      }
     },
     "ae2d36cb8eac4c5094fe7b11f935d74a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1d1354e458d42cb8fe1ac8e2664af61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b27246bc159e42fcb36a387feb59e5eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b27e3a123f81480191d6cb00d413e0d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a747496e51214ebb99dbd436f5c7ca49",
       "max": 15.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1cad92fea47b40cab2fae6a3a57c4880",
       "value": 15.0
      }
     },
     "b4f0e607f69a4c7c95dd63df77789bf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b73d304d97e845eb9b348454fe4eceeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7f13694fa064d2798e58ba0b8dcc644": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4aa9b36bb33403d9163ad62195dff70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c7657771be87496ba1cabe8e88587c2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6c4ca230b94b4d978ad24ab33ed9d37e",
       "placeholder": "​",
       "style": "IPY_MODEL_671f342fb94f43cfaf4b11b7b116caae",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "c7c672f7da0e4a7da0e424a3d771184c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18fce1cc1de64899bc2326647c5ae36c",
       "placeholder": "​",
       "style": "IPY_MODEL_88e92dd561f7441bae03b4fe4613d3a8",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "ca5fc76012f44ab4a603b7b1cff3a5d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "cdfc3d8d85ac496d91e04e8cd89514fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ceb5c908b9e14c7bb4fcf620ac9225a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f67b2ec5a9de4c77804b32e2d3a9b049",
       "placeholder": "​",
       "style": "IPY_MODEL_2f4ec60273ae4b2198ec533b594933d5",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "d1aa346f2daa4c3582058910271d49b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2c88f18db494b2ab395e9ae32fed6cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d41109ef9b6940dc984079ad9beba801": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6844c8a87b344f29f453d141a2d56d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9a971b204ff4458b182bf13f8ef157d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "da3dd6215181466ea422dd72c4fdb1bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dca14628b35d420e843d32fca05476ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de088b18db7347d9ac1ffebc4520e040": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e47f7fa0a1e542afbcbe941c7cbc0ec6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a9fa9c8786a74f21bd3eb851f107219b",
        "IPY_MODEL_ea58b7bae36b4fce8d6aeae99a24dbe1"
       ],
       "layout": "IPY_MODEL_da3dd6215181466ea422dd72c4fdb1bb"
      }
     },
     "e5b01966cec44e918b312e287db0bd56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e6de69b902e44371a8f06dabdded14be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "e7c15905b57544afa6ec870b1491908d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_536ccdc02e3d44238f5c2e2c4d003824",
        "IPY_MODEL_31fe7b1f74d0433682493dab2cdf6e52"
       ],
       "layout": "IPY_MODEL_25ceb38ed0b145668ee8c4632270f839"
      }
     },
     "ea58b7bae36b4fce8d6aeae99a24dbe1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1aa346f2daa4c3582058910271d49b3",
       "placeholder": "​",
       "style": "IPY_MODEL_fd331f28886e4c6b9d925fb22821db1b",
       "value": " 15/15 [00:16&lt;00:00,  1.10s/it]"
      }
     },
     "eb8e8ae439cc498181e79abc3d96b036": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebef13bbd30c4c8b9e534c0003f29d87": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee71222b373b490cb44e30468035b3d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f48d5d040bb4455bb40283599fff7608": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f67b2ec5a9de4c77804b32e2d3a9b049": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6fea3f5d42542abb8796fafb0914d66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f83f7f09820c4aa8aef584dc4bdb368e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f8783837c5274aada680cb22d7fe904b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f89e5a68206047d5b40c9b7dbfd8562b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a2dba31274d4e41af34e829169c875c",
        "IPY_MODEL_60b57f5835be41bf8740671531656c1c"
       ],
       "layout": "IPY_MODEL_b73d304d97e845eb9b348454fe4eceeb"
      }
     },
     "fb6976de2fda406dbdbef6fb439da801": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b27e3a123f81480191d6cb00d413e0d1",
        "IPY_MODEL_6d64d297b7534e1a887885cc11d620f0"
       ],
       "layout": "IPY_MODEL_04615368d5604dc4813d1283af6e1731"
      }
     },
     "fc2ae269bec54770bea39b45af3e6f65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc3264e7e63440bcb3e5d40bec8dd94e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc5277289c284541af766d05e24351e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fd331f28886e4c6b9d925fb22821db1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ffa5a42f8eeb40d0b9fb6c28d4e44410": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
